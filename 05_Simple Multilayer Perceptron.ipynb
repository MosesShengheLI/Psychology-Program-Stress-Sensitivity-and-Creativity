{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6c3dca-b39f-4f93-839c-f31642d13e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "import matplotlib.lines as mlines\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import shap\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ecfce4-ccc1-49ec-a541-014a184ab17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              0\n",
       "gender           0\n",
       "SPS              0\n",
       "FA1              0\n",
       "FA2              0\n",
       "FA3              0\n",
       "FA4              0\n",
       "RAT              0\n",
       "BT               0\n",
       "CSE              0\n",
       "Group            0\n",
       "Stage1           0\n",
       "Stage2           0\n",
       "Num              0\n",
       "Stage2_Stage1    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df here stands for exactly the same as it does in file \"01\", \"02\" \"03\" and \"04\";\n",
    "df = pd.read_csv(\"Raw Data.csv\") # The name of participants have been removed right after the experiment.\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5054023-42ca-4127-8406-86a49273b9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>SPS</th>\n",
       "      <th>FA1</th>\n",
       "      <th>FA2</th>\n",
       "      <th>FA3</th>\n",
       "      <th>FA4</th>\n",
       "      <th>RAT</th>\n",
       "      <th>BT</th>\n",
       "      <th>CSE</th>\n",
       "      <th>Group</th>\n",
       "      <th>Stage1</th>\n",
       "      <th>Stage2</th>\n",
       "      <th>Num</th>\n",
       "      <th>Stage2_Stage1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.901478</td>\n",
       "      <td>1.773399</td>\n",
       "      <td>101.049261</td>\n",
       "      <td>5.201970</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>12.142857</td>\n",
       "      <td>9.192118</td>\n",
       "      <td>6.078818</td>\n",
       "      <td>4.901478</td>\n",
       "      <td>27.162562</td>\n",
       "      <td>0.507389</td>\n",
       "      <td>13.487685</td>\n",
       "      <td>21.334975</td>\n",
       "      <td>108.931034</td>\n",
       "      <td>7.847291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.210575</td>\n",
       "      <td>0.419667</td>\n",
       "      <td>11.640980</td>\n",
       "      <td>3.329079</td>\n",
       "      <td>4.915841</td>\n",
       "      <td>6.703353</td>\n",
       "      <td>4.110785</td>\n",
       "      <td>2.247924</td>\n",
       "      <td>2.036826</td>\n",
       "      <td>6.612183</td>\n",
       "      <td>0.501181</td>\n",
       "      <td>7.227121</td>\n",
       "      <td>9.768413</td>\n",
       "      <td>62.101683</td>\n",
       "      <td>8.050050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>161.500000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age      gender         SPS         FA1         FA2         FA3  \\\n",
       "count  203.000000  203.000000  203.000000  203.000000  203.000000  203.000000   \n",
       "mean    19.901478    1.773399  101.049261    5.201970    8.285714   12.142857   \n",
       "std      1.210575    0.419667   11.640980    3.329079    4.915841    6.703353   \n",
       "min     18.000000    1.000000   65.000000    1.000000    1.000000    1.000000   \n",
       "25%     19.000000    2.000000   94.000000    3.000000    5.000000    7.000000   \n",
       "50%     20.000000    2.000000  102.000000    4.000000    7.000000   11.000000   \n",
       "75%     21.000000    2.000000  109.000000    7.000000   11.000000   15.500000   \n",
       "max     22.000000    2.000000  128.000000   18.000000   23.000000   34.000000   \n",
       "\n",
       "              FA4         RAT          BT         CSE       Group      Stage1  \\\n",
       "count  203.000000  203.000000  203.000000  203.000000  203.000000  203.000000   \n",
       "mean     9.192118    6.078818    4.901478   27.162562    0.507389   13.487685   \n",
       "std      4.110785    2.247924    2.036826    6.612183    0.501181    7.227121   \n",
       "min      2.000000    0.000000    0.000000    7.000000    0.000000    3.000000   \n",
       "25%      6.000000    5.000000    3.000000   23.000000    0.000000    8.000000   \n",
       "50%      9.000000    6.000000    5.000000   28.000000    1.000000   12.000000   \n",
       "75%     11.500000    8.000000    6.000000   32.000000    1.000000   17.000000   \n",
       "max     22.000000   11.000000   10.000000   42.000000    1.000000   37.000000   \n",
       "\n",
       "           Stage2         Num  Stage2_Stage1  \n",
       "count  203.000000  203.000000     203.000000  \n",
       "mean    21.334975  108.931034       7.847291  \n",
       "std      9.768413   62.101683       8.050050  \n",
       "min      5.000000    1.000000     -17.000000  \n",
       "25%     14.000000   55.500000       2.000000  \n",
       "50%     19.000000  109.000000       7.000000  \n",
       "75%     28.000000  161.500000      13.000000  \n",
       "max     49.000000  216.000000      35.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "843adf0f-73d8-4c78-88b6-35bc053aed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 68.4079\n",
      "Epoch 20/50, Loss: 25.0095\n",
      "Epoch 30/50, Loss: 20.9317\n",
      "Epoch 40/50, Loss: 19.6867\n",
      "Epoch 50/50, Loss: 18.7646\n",
      "Test MSE: 37.1104\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 1. Prepare data (example dataset, replace with your df_ml)\n",
    "# ============================\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "df_ml = pd.DataFrame({\n",
    "    \"SPS\": np.random.randn(n_samples) * 5 + 50,\n",
    "    \"CSE\": np.random.randn(n_samples) * 3 + 20,\n",
    "    \"age\": np.random.randint(18, 40, n_samples),\n",
    "    \"gender\": np.random.choice([1, 2], n_samples),  # 1=Male, 2=Female\n",
    "    \"group\": np.random.choice([0, 1], n_samples),   # experimental group\n",
    "})\n",
    "\n",
    "# Construct target variable (CreativityChange)\n",
    "df_ml[\"CreativityChange\"] = 0.5 * df_ml[\"SPS\"] + 0.3 * df_ml[\"CSE\"] + np.random.randn(n_samples) * 5\n",
    "\n",
    "categorical_cols = [\"gender\", \"group\"]\n",
    "numeric_cols = [\"SPS\", \"CSE\", \"age\"]\n",
    "target_col = \"CreativityChange\"\n",
    "\n",
    "# ============================\n",
    "# 2. Preprocessing\n",
    "# ============================\n",
    "# One-hot encode categorical variables and keep numeric as-is\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), categorical_cols),\n",
    "    (\"num\", \"passthrough\", numeric_cols)\n",
    "])\n",
    "\n",
    "X = preprocessor.fit_transform(df_ml[categorical_cols + numeric_cols])\n",
    "y = df_ml[target_col].values.reshape(-1, 1)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# ============================\n",
    "# 3. Train-test split\n",
    "# ============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# ============================\n",
    "# 4. Define MLP model (regression)\n",
    "# ============================\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)  # single output for regression\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP(X_train.shape[1])\n",
    "\n",
    "# ============================\n",
    "# 5. Loss function and optimizer\n",
    "# ============================\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# ============================\n",
    "# 6. Training loop\n",
    "# ============================\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# ============================\n",
    "# 7. Evaluation\n",
    "# ============================\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test_tensor).numpy()\n",
    "    mse = np.mean((preds - y_test) ** 2)\n",
    "    print(f\"Test MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d358c102-2612-4f40-9c1b-edf5ddaba980",
   "metadata": {},
   "source": [
    "# Stage Summary of MLP Regression Training  \n",
    "\n",
    "### **1. Training Progress**  \n",
    "- The model was trained for **50 epochs** using an MLP with two hidden layers (32 → 16 → 1).  \n",
    "- The training loss showed a **consistent downward trend**:  \n",
    "  - **Epoch 10:** Loss ≈ 53.8  \n",
    "  - **Epoch 20:** Loss ≈ 25.4  \n",
    "  - **Epoch 30:** Loss ≈ 21.8  \n",
    "  - **Epoch 40:** Loss ≈ 20.4  \n",
    "  - **Epoch 50:** Loss ≈ 19.5  \n",
    "- This indicates that the model successfully **learned patterns from the data**, with diminishing improvements in later epochs.\n",
    "\n",
    "### **2. Model Performance**  \n",
    "- The final **test Mean Squared Error (MSE)** was **38.59**.  \n",
    "- While the model generalizes reasonably, the test error suggests that predictions are still not highly accurate, and there may be room for further optimization.\n",
    "\n",
    "### **3. Key Observations**  \n",
    "- The model converged steadily, without signs of severe overfitting or underfitting within 50 epochs.  \n",
    "- The gap between training loss (~19.5) and test MSE (~38.6) suggests some **generalization gap**, possibly due to limited data or model complexity.\n",
    "\n",
    "### **4. Next Steps**  \n",
    "- Consider **hyperparameter tuning** (e.g., learning rate, hidden units, batch size).  \n",
    "- Experiment with **regularization techniques** (Dropout, L2 weight decay) to reduce overfitting.  \n",
    "- Increase the dataset size or perform **feature engineering** to improve predictive accuracy.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3cd41-ba43-43a9-841d-aaff8c685ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SPS Creativity 251001)",
   "language": "python",
   "name": "sps_creativity_251001"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
